{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Option 1\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import warnings\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/13 15:02:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "appName = \"Big Data Analytics\"\n",
    "master = \"local[*]\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_properties={}\n",
    "db_properties['username']=\"postgres\"\n",
    "db_properties['password']=\"\"\n",
    "db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "db_properties['table']=\"fifa.fifa\"\n",
    "db_properties['driver']=\"org.postgresql.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = spark.read.csv('./Data/players_15.csv', header = True)\n",
    "combined_df = df_male.withColumn(\"year\", lit(2015))\n",
    "combined_df = combined_df.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *combined_df.columns)\n",
    "combined_df = combined_df.withColumn(\"gender\", lit(\"Male\"))\n",
    "folder_path = \"./Data\"\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name == \"players_15.csv\":\n",
    "        continue\n",
    "    year = \"20\" + file_name[-6:-4]\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df_read = spark.read.csv(file_path, header = True)\n",
    "    df_read = df_read.withColumn(\"year\", lit(int(year)))\n",
    "    df_read = df_read.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *df_read.columns)\n",
    "    if \"female\" in file_name:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Female\"))\n",
    "    else:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Male\"))\n",
    "    combined_df = combined_df.union(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to PostgreSQL\n",
    "combined_df.write.format(\"jdbc\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".option(\"url\", db_properties['url'])\\\n",
    ".option(\"dbtable\", db_properties['table'])\\\n",
    ".option(\"user\", db_properties['username'])\\\n",
    ".option(\"password\", db_properties['password'])\\\n",
    ".option(\"Driver\", db_properties['driver'])\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from PostgreSQL to verify\n",
    "df_from_postgres = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", db_properties['url'])\\\n",
    "    .option(\"dbtable\", db_properties['table'])\\\n",
    "    .option(\"user\", db_properties['username'])\\\n",
    "    .option(\"password\", db_properties['password'])\\\n",
    "    .option(\"Driver\", db_properties['driver'])\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id',\n",
       " 'sofifa_id',\n",
       " 'player_url',\n",
       " 'short_name',\n",
       " 'long_name',\n",
       " 'player_positions',\n",
       " 'overall',\n",
       " 'potential',\n",
       " 'value_eur',\n",
       " 'wage_eur',\n",
       " 'age',\n",
       " 'dob',\n",
       " 'height_cm',\n",
       " 'weight_kg',\n",
       " 'club_team_id',\n",
       " 'club_name',\n",
       " 'league_name',\n",
       " 'league_level',\n",
       " 'club_position',\n",
       " 'club_jersey_number',\n",
       " 'club_loaned_from',\n",
       " 'club_joined',\n",
       " 'club_contract_valid_until',\n",
       " 'nationality_id',\n",
       " 'nationality_name',\n",
       " 'nation_team_id',\n",
       " 'nation_position',\n",
       " 'nation_jersey_number',\n",
       " 'preferred_foot',\n",
       " 'weak_foot',\n",
       " 'skill_moves',\n",
       " 'international_reputation',\n",
       " 'work_rate',\n",
       " 'body_type',\n",
       " 'real_face',\n",
       " 'release_clause_eur',\n",
       " 'player_tags',\n",
       " 'player_traits',\n",
       " 'pace',\n",
       " 'shooting',\n",
       " 'passing',\n",
       " 'dribbling',\n",
       " 'defending',\n",
       " 'physic',\n",
       " 'attacking_crossing',\n",
       " 'attacking_finishing',\n",
       " 'attacking_heading_accuracy',\n",
       " 'attacking_short_passing',\n",
       " 'attacking_volleys',\n",
       " 'skill_dribbling',\n",
       " 'skill_curve',\n",
       " 'skill_fk_accuracy',\n",
       " 'skill_long_passing',\n",
       " 'skill_ball_control',\n",
       " 'movement_acceleration',\n",
       " 'movement_sprint_speed',\n",
       " 'movement_agility',\n",
       " 'movement_reactions',\n",
       " 'movement_balance',\n",
       " 'power_shot_power',\n",
       " 'power_jumping',\n",
       " 'power_stamina',\n",
       " 'power_strength',\n",
       " 'power_long_shots',\n",
       " 'mentality_aggression',\n",
       " 'mentality_interceptions',\n",
       " 'mentality_positioning',\n",
       " 'mentality_vision',\n",
       " 'mentality_penalties',\n",
       " 'mentality_composure',\n",
       " 'defending_marking_awareness',\n",
       " 'defending_standing_tackle',\n",
       " 'defending_sliding_tackle',\n",
       " 'goalkeeping_diving',\n",
       " 'goalkeeping_handling',\n",
       " 'goalkeeping_kicking',\n",
       " 'goalkeeping_positioning',\n",
       " 'goalkeeping_reflexes',\n",
       " 'goalkeeping_speed',\n",
       " 'ls',\n",
       " 'st',\n",
       " 'rs',\n",
       " 'lw',\n",
       " 'lf',\n",
       " 'cf',\n",
       " 'rf',\n",
       " 'rw',\n",
       " 'lam',\n",
       " 'cam',\n",
       " 'ram',\n",
       " 'lm',\n",
       " 'lcm',\n",
       " 'cm',\n",
       " 'rcm',\n",
       " 'rm',\n",
       " 'lwb',\n",
       " 'ldm',\n",
       " 'cdm',\n",
       " 'rdm',\n",
       " 'rwb',\n",
       " 'lb',\n",
       " 'lcb',\n",
       " 'cb',\n",
       " 'rcb',\n",
       " 'rb',\n",
       " 'gk',\n",
       " 'player_face_url',\n",
       " 'club_logo_url',\n",
       " 'club_flag_url',\n",
       " 'nation_logo_url',\n",
       " 'nation_flag_url',\n",
       " 'year',\n",
       " 'gender']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144323"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_spark(spark, db_properties):\n",
    "    df_from_postgres = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_properties['url'])\\\n",
    "        .option(\"dbtable\", db_properties['table'])\\\n",
    "        .option(\"user\", db_properties['username'])\\\n",
    "        .option(\"password\", db_properties['password'])\\\n",
    "        .option(\"Driver\", db_properties['driver'])\\\n",
    "        .load()\n",
    "    df = df_from_postgres.filter(df_from_postgres[\"gender\"] == \"Male\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clubs_with_contracts_ending(spark, db_properties, X, Y, Z):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    df_filtered = df.filter(col(\"year\") == X)\n",
    "    df_expiring = df_filtered.filter(col(\"club_contract_valid_until\").cast(\"int\") >= Z)\n",
    "    result = df_expiring.groupBy(\"club_name\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .limit(Y)\n",
    "    return result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clubs_by_average_age(spark, db_properties, X, Y, highest=True):\n",
    "    if X <= 0:\n",
    "        return \"X must be a positive integer\"\n",
    "    if Y < 2015 or Y > 2022:\n",
    "        return \"Y must be a year between 2015 and 2022 inclusively\"\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    \n",
    "    # Filter data for specified year Y\n",
    "    df_filtered = df.filter(col(\"year\") == Y)\n",
    "    avg_age_per_club = df_filtered.groupBy(\"club_name\") \\\n",
    "        .agg(round(avg(\"age\").cast(\"float\"),2).alias(\"average_age\"))\n",
    "    if highest:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(desc(\"average_age\"))\n",
    "    else:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(asc(\"average_age\"))\n",
    "\n",
    "    top_clubs = sorted_clubs.limit(X)\n",
    "    last_club = top_clubs.collect()[-1]\n",
    "    threshold_age = last_club[\"average_age\"]\n",
    "    if highest:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") >= threshold_age).collect()\n",
    "    else:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") <= threshold_age).collect()\n",
    "    return result_clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_popular_nationality(spark, db_properties):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    # df_filtered = df.filter((col(\"year\") >= 2015) & (col(\"year\") <= 2022))\n",
    "    nationality_counts = df.groupBy(\"year\", \"nationality_name\") \\\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "    # Create a window partitioned by year and ordered by count descending\n",
    "    window = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    # Add row number within each year partition\n",
    "    ranked_nationalities = nationality_counts.withColumn(\"rank\", row_number().over(window))\n",
    "    # Filter for the top nationality for each year\n",
    "    most_popular_nationalities = ranked_nationalities.filter(col(\"rank\") == 1) \\\n",
    "        .select(\"year\", \"nationality_name\", \"count\") \\\n",
    "        .orderBy(\"year\")\n",
    "    \n",
    "    return most_popular_nationalities.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clubs = get_top_clubs_with_contracts_ending(spark=spark, db_properties=db_properties, X=2021, Y=10, Z=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='GwangJu FC', count=28),\n",
       " Row(club_name='Zamora Fútbol Club', count=27),\n",
       " Row(club_name='Club Plaza de Deportes Colonia', count=27),\n",
       " Row(club_name='SL Benfica', count=26),\n",
       " Row(club_name='Club Deportivo El Nacional', count=26),\n",
       " Row(club_name='Sociedad Deportiva Aucas', count=26),\n",
       " Row(club_name='Gangwon FC', count=26),\n",
       " Row(club_name='Club Atlético Nacional Potosí', count=26),\n",
       " Row(club_name='Busan IPark', count=26),\n",
       " Row(club_name='Club Sportivo Luqueño', count=25)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs_by_age = find_clubs_by_average_age(spark=spark, db_properties=db_properties, X=10, Y=2017, highest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='Sevilla Atlético', average_age=19.920000076293945),\n",
       " Row(club_name='Swindon Town', average_age=21.3700008392334),\n",
       " Row(club_name='CD Huachipato', average_age=21.40999984741211),\n",
       " Row(club_name='FC Nordsjælland', average_age=21.40999984741211),\n",
       " Row(club_name='FC Twente', average_age=21.59000015258789),\n",
       " Row(club_name='Envigado FC', average_age=21.610000610351562),\n",
       " Row(club_name='KRC Genk', average_age=21.6299991607666),\n",
       " Row(club_name='Crewe Alexandra', average_age=21.81999969482422),\n",
       " Row(club_name='Barnsley', average_age=21.8700008392334),\n",
       " Row(club_name='Ajax', average_age=21.969999313354492)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_by_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_nationalities = get_most_popular_nationality(spark=spark, db_properties=db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2015, nationality_name='England', count=1627),\n",
       " Row(year=2016, nationality_name='England', count=1519),\n",
       " Row(year=2017, nationality_name='England', count=1627),\n",
       " Row(year=2018, nationality_name='England', count=1633),\n",
       " Row(year=2019, nationality_name='England', count=1625),\n",
       " Row(year=2020, nationality_name='England', count=1670),\n",
       " Row(year=2021, nationality_name='England', count=1685),\n",
       " Row(year=2022, nationality_name='England', count=1719)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = read_from_spark(spark, db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF for safe evaluation\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return float(eval(str(x)))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF for trait assignment\n",
    "def assign_traits(player_positions, *traits):\n",
    "    traits = [float(t) if t is not None else None for t in traits]\n",
    "    if player_positions and 'GK' in player_positions:\n",
    "        return traits[6:12]\n",
    "    else:\n",
    "        return traits[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engineering_pipeline(spark_df):\n",
    "    # Drop columns\n",
    "    columns_to_drop = ['record_id', 'sofifa_id', 'player_url', 'short_name', 'long_name',\n",
    "                       'dob', 'club_name', 'league_name', 'club_position', 'club_jersey_number', 'club_loaned_from',\n",
    "                       'club_contract_valid_until', 'nationality_id', 'nationality_name', 'nation_team_id',\n",
    "                       'nation_position', 'nation_jersey_number', 'real_face', 'player_tags', 'player_traits', \n",
    "                       'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url',\n",
    "                       'year', 'gender', 'club_joined']\n",
    "\n",
    "    positions = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw',\n",
    "             'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm',\n",
    "             'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb',\n",
    "             'rcb', 'rb', 'gk']\n",
    "    attacking_positions = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw',\n",
    "                           'lam', 'cam', 'ram']\n",
    "    midfield_positions = ['lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm',\n",
    "                          'ldm', 'cdm', 'rdm']\n",
    "    defensive_positions = ['rwb', 'lb', 'lcb', 'cb', 'lwb', 'rcb', 'rb',\n",
    "                           'ldm', 'cdm', 'rdm']\n",
    "    gk_positions = ['gk']\n",
    "\n",
    "    # Define main traits\n",
    "    main_traits_to_merge = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', \n",
    "                            'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
    "                            'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']\n",
    "\n",
    "    # List of skill columns to average\n",
    "    skill_columns = ['skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control']\n",
    "\n",
    "    #Trait1 = pace/goalkeeping_diving\n",
    "    #Trait2 = shooting/goalkeeping_handling\n",
    "    #Trait3 = passing/goalkeeping_kicking\n",
    "    #Trait4 = dribbling/goalkeeping_positioning\n",
    "    #Trait5 = defending/goalkeeping_reflexes\n",
    "    #Trait6 = physic/goalkeeping_speed\n",
    "    \n",
    "    safe_eval_udf = F.udf(safe_eval, FloatType())\n",
    "    assign_traits_udf = udf(assign_traits, ArrayType(FloatType()))\n",
    "    \n",
    "    #Drop Columns\n",
    "    spark_df = spark_df.drop(*columns_to_drop)\n",
    "    \n",
    "    # Apply safe_eval to position columns\n",
    "    for pos in positions:\n",
    "        spark_df = spark_df.withColumn(pos, safe_eval_udf(pos))\n",
    "\n",
    "    #Add new columns 'average_val_attacking', 'average_val_midfield', 'average_val_defensive', 'average_val_gk'\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_attacking', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in attacking_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in attacking_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_midfield', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in midfield_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in midfield_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_defensive', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in defensive_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in defensive_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_gk', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in gk_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in gk_positions]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Apply trait assignment\n",
    "    spark_df = spark_df.withColumn('traits', \n",
    "        assign_traits_udf(col('player_positions'), *[col(trait) for trait in main_traits_to_merge])\n",
    "    )\n",
    "    \n",
    "    # Extract individual traits\n",
    "    for i in range(1, 7):\n",
    "        spark_df = spark_df.withColumn(f'trait{i}', col('traits').getItem(i-1))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    spark_df = spark_df.drop(*positions, *main_traits_to_merge, 'player_positions', 'traits')\n",
    "    \n",
    "    # Drop rows with null values in specific columns\n",
    "    spark_df = spark_df.na.drop(subset=['wage_eur', 'value_eur', 'trait6'])\n",
    "    \n",
    "    # Drop additional columns\n",
    "    spark_df = spark_df.drop('release_clause_eur', 'league_level')\n",
    "    \n",
    "    # Fill null values in club_team_id with -1\n",
    "    spark_df = spark_df.fillna({'club_team_id': -1})\n",
    "\n",
    "    #Average out skills as highly correlated\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'corr_av_skills', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in skill_columns]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in skill_columns]))\n",
    "        )\n",
    "    )\n",
    "    #Drop the skills as added one new average skill column\n",
    "    spark_df = spark_df.drop('skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control')\n",
    "\n",
    "    #Drop movement_acceleration as highly correlated to movement_speed\n",
    "    spark_df = spark_df.drop('movement_acceleration')\n",
    "\n",
    "    #Drop movement_acceleration as highly correlated to movement_speed\n",
    "    spark_df = spark_df.drop('preferred_foot')\n",
    "\n",
    "    s = spark_df.toPandas()\n",
    "    print(s)\n",
    "    print(f'Shape {s.shape}')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       overall potential    value_eur  wage_eur age height_cm weight_kg  \\\n",
      "0           93        93   78000000.0  320000.0  34       170        72   \n",
      "1           92        92  119500000.0  270000.0  32       185        81   \n",
      "2           91        91   45000000.0  270000.0  36       187        83   \n",
      "3           91        91  129000000.0  270000.0  29       175        68   \n",
      "4           91        91  125500000.0  350000.0  30       181        70   \n",
      "...        ...       ...          ...       ...  ..       ...       ...   \n",
      "140176      59        62     160000.0    3000.0  25       183        76   \n",
      "140177      59        67     230000.0    2000.0  22       177        75   \n",
      "140178      59        73     350000.0    2000.0  20       176        70   \n",
      "140179      59        67     240000.0    3000.0  23       169        57   \n",
      "140180      59        63     160000.0    3000.0  25       176        74   \n",
      "\n",
      "       club_team_id weak_foot skill_moves  ... average_val_midfield  \\\n",
      "0              73.0         4           4  ...            85.090909   \n",
      "1              21.0         4           4  ...            81.545455   \n",
      "2              11.0         4           5  ...            79.454545   \n",
      "3              73.0         5           5  ...            82.545455   \n",
      "4              10.0         5           4  ...            88.818182   \n",
      "...             ...       ...         ...  ...                  ...   \n",
      "140176     112510.0         3           1  ...            23.727273   \n",
      "140177       1443.0         3           2  ...            53.000000   \n",
      "140178         17.0         3           2  ...            52.454545   \n",
      "140179     112395.0         4           3  ...            50.909091   \n",
      "140180     112172.0         3           2  ...            52.636364   \n",
      "\n",
      "       average_val_defensive average_val_gk trait1 trait2 trait3 trait4  \\\n",
      "0                       62.6           22.0   85.0   92.0   91.0   95.0   \n",
      "1                       65.8           22.0   78.0   92.0   79.0   86.0   \n",
      "2                       61.2           23.0   87.0   94.0   80.0   88.0   \n",
      "3                       62.7           23.0   91.0   83.0   86.0   94.0   \n",
      "4                       78.5           24.0   76.0   86.0   93.0   88.0   \n",
      "...                      ...            ...    ...    ...    ...    ...   \n",
      "140176                  22.6           59.0   61.0   60.0   54.0   59.0   \n",
      "140177                  44.2           16.0   77.0   51.0   54.0   58.0   \n",
      "140178                  39.4           14.0   61.0   57.0   58.0   65.0   \n",
      "140179                  38.5           16.0   91.0   55.0   45.0   66.0   \n",
      "140180                  57.5           16.0   70.0   40.0   51.0   58.0   \n",
      "\n",
      "       trait5 trait6 corr_av_skills  \n",
      "0        34.0   65.0           94.0  \n",
      "1        44.0   82.0           81.4  \n",
      "2        34.0   75.0           83.6  \n",
      "3        37.0   63.0           89.2  \n",
      "4        64.0   78.0           88.0  \n",
      "...       ...    ...            ...  \n",
      "140176   59.0   31.0           16.4  \n",
      "140177   27.0   61.0           51.4  \n",
      "140178   24.0   50.0           59.4  \n",
      "140179   19.0   48.0           43.6  \n",
      "140180   58.0   59.0           49.8  \n",
      "\n",
      "[140181 rows x 47 columns]\n",
      "Shape (140181, 47)\n"
     ]
    }
   ],
   "source": [
    "s = data_engineering_pipeline(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From correlation analysis\n",
    "average - skill columns\n",
    "remove - movement_acceleration\n",
    "Preffered foot is not correlated to overall. so drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentality_composure\n",
       "False    108947\n",
       "True      31234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['mentality_composure'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For mentality_composure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "train_data = s.dropna(subset=['mentality_composure'])\n",
    "X = train_data[['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']]\n",
    "Y = train_data['mentality_composure']\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Predict missing values\n",
    "X_missing = s[s['mentality_composure'].isnull()][['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']]\n",
    "predicted_values = model.predict(X_missing)\n",
    "rounded_predicted_values = np.round(predicted_values).astype(int)\n",
    "# Impute the predicted values\n",
    "s.loc[s['mentality_composure'].isnull(), 'mentality_composure'] = rounded_predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentality_composure\n",
       "False    140181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['mentality_composure'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = s\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('overall', axis=1)\n",
    "y = df['overall']\n",
    "\n",
    "# Split the data into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train+validation into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have X_train, X_val, X_test\n",
    "\n",
    "# Define the order for work_rate\n",
    "work_rate_order = ['Low/Low', 'Low/Medium', 'Low/High',\n",
    "                   'Medium/Low', 'Medium/Medium', 'Medium/High',\n",
    "                   'High/Low', 'High/Medium', 'High/High']\n",
    "\n",
    "# Initialize OrdinalEncoder for work_rate\n",
    "work_rate_encoder = OrdinalEncoder(categories=[work_rate_order])\n",
    "\n",
    "# Encode work_rate\n",
    "X_train['work_rate_encoded'] = work_rate_encoder.fit_transform(X_train[['work_rate']])\n",
    "X_val['work_rate_encoded'] = work_rate_encoder.transform(X_val[['work_rate']])\n",
    "X_test['work_rate_encoded'] = work_rate_encoder.transform(X_test[['work_rate']])\n",
    "\n",
    "# Perform one-hot encoding for body_type using pd.get_dummies\n",
    "X_train_body_type_dummies = pd.get_dummies(X_train['body_type'], prefix='body_type')\n",
    "X_val_body_type_dummies = pd.get_dummies(X_val['body_type'], prefix='body_type')\n",
    "X_test_body_type_dummies = pd.get_dummies(X_test['body_type'], prefix='body_type')\n",
    "\n",
    "# Combine the original DataFrames with the encoded columns\n",
    "X_train = pd.concat([X_train, X_train_body_type_dummies], axis=1)\n",
    "X_val = pd.concat([X_val, X_val_body_type_dummies], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_body_type_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'work_rate' and 'body_type' columns\n",
    "X_train = X_train.drop(['work_rate', 'body_type'], axis=1)\n",
    "X_val = X_val.drop(['work_rate', 'body_type'], axis=1)\n",
    "X_test = X_test.drop(['work_rate', 'body_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train = pd.to_numeric(y_train)\n",
    "y_val = pd.to_numeric(y_val)\n",
    "y_test = pd.to_numeric(y_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).reshape(-1, 1).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1).to(device)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Multi-layer Perceptron (MLP)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=70):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            train_true.extend(targets.cpu().numpy())\n",
    "            train_pred.extend(outputs.detach().cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "                \n",
    "                val_true.extend(targets.cpu().numpy())\n",
    "                val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        train_r2 = r2_score(train_true, train_pred)\n",
    "        val_r2 = r2_score(val_true, val_pred)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, Train R2: {train_r2:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val R2: {val_r2:.4f}')\n",
    "    \n",
    "    return val_loss, val_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model_class, param_grid):\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_val_r2 = -float('inf')\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        current_params = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {current_params}\")\n",
    "\n",
    "        if model_class == MLP:\n",
    "            model = model_class(input_size=X_train.shape[1], hidden_size=current_params['hidden_size'])\n",
    "        elif model_class == LinearRegression:\n",
    "            model = model_class(input_size=X_train.shape[1])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model class\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=current_params['lr'])\n",
    "        criterion = nn.MSELoss()\n",
    "        train_loader = DataLoader(train_dataset, batch_size=current_params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=current_params['batch_size'])\n",
    "\n",
    "        val_loss, val_r2 = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_r2 = val_r2\n",
    "            best_val_loss = val_loss\n",
    "            best_params = current_params\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    return best_params, best_val_loss, best_model, best_val_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(model_class):\n",
    "    input_size = X_test_tensor.shape[1]\n",
    "    if model_class == \"LR\":\n",
    "        model = LinearRegression(input_size)\n",
    "        model.load_state_dict(torch.load('./best_linear_model.pth'))\n",
    "    elif model_class == \"MLP\":\n",
    "        model = MLP(input_size, mlp_best_params['hidden_size'])\n",
    "        model.load_state_dict(torch.load('./best_mlp_model.pth'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor)\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    \n",
    "    r2 = r2_score(y_test_np, y_pred_np)\n",
    "    mse = mean_squared_error(y_test_np, y_pred_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids\n",
    "mlp_param_grid = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'batch_size': [32, 64],\n",
    "    'hidden_size': [32, 64]\n",
    "}\n",
    "\n",
    "linear_param_grid = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'batch_size': [32, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MLP model...\n",
      "Training with parameters: {'lr': 0.001, 'batch_size': 32, 'hidden_size': 32}\n",
      "Epoch [10/50], Train Loss: 0.8847, Train R2: 0.9823, Val Loss: 0.8576, Val R2: 0.9828\n",
      "Epoch [20/50], Train Loss: 0.6477, Train R2: 0.9871, Val Loss: 0.6679, Val R2: 0.9866\n",
      "Epoch [30/50], Train Loss: 0.5924, Train R2: 0.9882, Val Loss: 0.5954, Val R2: 0.9881\n",
      "Epoch [40/50], Train Loss: 0.5653, Train R2: 0.9887, Val Loss: 0.5672, Val R2: 0.9886\n",
      "Epoch [50/50], Train Loss: 0.5567, Train R2: 0.9889, Val Loss: 0.5739, Val R2: 0.9885\n",
      "Training with parameters: {'lr': 0.001, 'batch_size': 32, 'hidden_size': 64}\n",
      "Epoch [10/50], Train Loss: 0.7999, Train R2: 0.9840, Val Loss: 0.8791, Val R2: 0.9824\n",
      "Epoch [20/50], Train Loss: 0.6304, Train R2: 0.9874, Val Loss: 0.6195, Val R2: 0.9876\n",
      "Epoch [30/50], Train Loss: 0.5921, Train R2: 0.9882, Val Loss: 0.5578, Val R2: 0.9888\n",
      "Epoch [40/50], Train Loss: 0.5677, Train R2: 0.9887, Val Loss: 0.5718, Val R2: 0.9885\n",
      "Epoch [50/50], Train Loss: 0.5541, Train R2: 0.9889, Val Loss: 0.5473, Val R2: 0.9890\n",
      "Training with parameters: {'lr': 0.001, 'batch_size': 64, 'hidden_size': 32}\n",
      "Epoch [10/50], Train Loss: 1.2900, Train R2: 0.9742, Val Loss: 1.2536, Val R2: 0.9749\n",
      "Epoch [20/50], Train Loss: 0.8024, Train R2: 0.9840, Val Loss: 0.7915, Val R2: 0.9842\n",
      "Epoch [30/50], Train Loss: 0.6615, Train R2: 0.9868, Val Loss: 0.6525, Val R2: 0.9869\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tune and train models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuning MLP model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m mlp_best_params, mlp_best_loss, mlp_best_model, mlp_best_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMLP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_param_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MLP parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlp_best_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MLP validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlp_best_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 21\u001b[0m, in \u001b[0;36mtune_hyperparameters\u001b[0;34m(model_class, param_grid)\u001b[0m\n\u001b[1;32m     18\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mcurrent_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mcurrent_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m val_loss, val_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n\u001b[1;32m     24\u001b[0m     best_val_r2 \u001b[38;5;241m=\u001b[39m val_r2\n",
      "Cell \u001b[0;32mIn[82], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m train_true \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m train_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     13\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniforge3/envs/spark_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    627\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/spark_env/lib/python3.9/site-packages/torch/autograd/profiler.py:688\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/spark_env/lib/python3.9/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tune and train models\n",
    "print(\"Tuning MLP model...\")\n",
    "mlp_best_params, mlp_best_loss, mlp_best_model, mlp_best_r2 = tune_hyperparameters(MLP, mlp_param_grid)\n",
    "print(f\"Best MLP parameters: {mlp_best_params}\")\n",
    "print(f\"Best MLP validation loss: {mlp_best_loss}\")\n",
    "print(f\"Best MLP validation loss: {mlp_best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Linear Regression model...\n",
      "Training with parameters: {'lr': 0.001, 'batch_size': 32}\n",
      "Epoch [10/70], Train Loss: 1572.5142, Train R2: -30.4099, Val Loss: 1465.1580, Val R2: -27.9239\n",
      "Epoch [20/70], Train Loss: 164.2907, Train R2: -2.2816, Val Loss: 132.5919, Val R2: -1.6175\n",
      "Epoch [30/70], Train Loss: 3.2340, Train R2: 0.9354, Val Loss: 3.2210, Val R2: 0.9364\n",
      "Epoch [40/70], Train Loss: 3.2315, Train R2: 0.9355, Val Loss: 3.2415, Val R2: 0.9360\n",
      "Epoch [50/70], Train Loss: 3.2284, Train R2: 0.9355, Val Loss: 3.2202, Val R2: 0.9364\n",
      "Epoch [60/70], Train Loss: 3.2295, Train R2: 0.9355, Val Loss: 3.2195, Val R2: 0.9364\n",
      "Epoch [70/70], Train Loss: 3.2283, Train R2: 0.9355, Val Loss: 3.2173, Val R2: 0.9365\n",
      "Training with parameters: {'lr': 0.001, 'batch_size': 64}\n",
      "Epoch [10/70], Train Loss: 2781.8867, Train R2: -54.5660, Val Loss: 2709.5183, Val R2: -52.4897\n",
      "Epoch [20/70], Train Loss: 1522.8350, Train R2: -29.4174, Val Loss: 1469.8756, Val R2: -28.0181\n",
      "Epoch [30/70], Train Loss: 647.3452, Train R2: -11.9302, Val Loss: 613.6497, Val R2: -11.1148\n",
      "Epoch [40/70], Train Loss: 149.1224, Train R2: -1.9786, Val Loss: 133.9107, Val R2: -1.6439\n",
      "Epoch [50/70], Train Loss: 3.6790, Train R2: 0.9265, Val Loss: 3.3561, Val R2: 0.9337\n",
      "Epoch [60/70], Train Loss: 3.2291, Train R2: 0.9355, Val Loss: 3.2216, Val R2: 0.9364\n",
      "Epoch [70/70], Train Loss: 3.2279, Train R2: 0.9355, Val Loss: 3.2151, Val R2: 0.9365\n",
      "Training with parameters: {'lr': 0.01, 'batch_size': 32}\n",
      "Epoch [10/70], Train Loss: 3.3043, Train R2: 0.9340, Val Loss: 3.2589, Val R2: 0.9357\n",
      "Epoch [20/70], Train Loss: 3.3054, Train R2: 0.9340, Val Loss: 3.2975, Val R2: 0.9349\n",
      "Epoch [30/70], Train Loss: 3.3086, Train R2: 0.9339, Val Loss: 3.3726, Val R2: 0.9334\n",
      "Epoch [40/70], Train Loss: 3.3076, Train R2: 0.9339, Val Loss: 3.3430, Val R2: 0.9340\n",
      "Epoch [50/70], Train Loss: 3.3073, Train R2: 0.9339, Val Loss: 3.2647, Val R2: 0.9356\n",
      "Epoch [60/70], Train Loss: 3.3043, Train R2: 0.9340, Val Loss: 3.2463, Val R2: 0.9359\n",
      "Epoch [70/70], Train Loss: 3.3063, Train R2: 0.9340, Val Loss: 3.3103, Val R2: 0.9347\n",
      "Training with parameters: {'lr': 0.01, 'batch_size': 64}\n",
      "Epoch [10/70], Train Loss: 3.2832, Train R2: 0.9344, Val Loss: 3.2454, Val R2: 0.9359\n",
      "Epoch [20/70], Train Loss: 3.2794, Train R2: 0.9345, Val Loss: 3.3443, Val R2: 0.9340\n",
      "Epoch [30/70], Train Loss: 3.2772, Train R2: 0.9345, Val Loss: 3.3054, Val R2: 0.9347\n",
      "Epoch [40/70], Train Loss: 3.2775, Train R2: 0.9345, Val Loss: 3.3551, Val R2: 0.9338\n",
      "Epoch [50/70], Train Loss: 3.2721, Train R2: 0.9346, Val Loss: 3.2946, Val R2: 0.9350\n",
      "Epoch [60/70], Train Loss: 3.2773, Train R2: 0.9345, Val Loss: 3.2892, Val R2: 0.9351\n",
      "Epoch [70/70], Train Loss: 3.2748, Train R2: 0.9346, Val Loss: 3.2631, Val R2: 0.9356\n",
      "Best Linear Regression parameters: {'lr': 0.001, 'batch_size': 64}\n",
      "Best Linear Regression validation loss: 3.2151231188380143\n",
      "Best Linear Regression validation R2: 0.9365381556734642\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Linear Regression model...\")\n",
    "linear_best_params, linear_best_loss, linear_best_model, linear_best_r2 = tune_hyperparameters(LinearRegression, linear_param_grid)\n",
    "print(f\"Best Linear Regression parameters: {linear_best_params}\")\n",
    "print(f\"Best Linear Regression validation loss: {linear_best_loss}\")\n",
    "print(f\"Best Linear Regression validation R2: {linear_best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "torch.save(mlp_best_model, 'best_mlp_model.pth')\n",
    "torch.save(linear_best_model, 'best_linear_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9363\n",
      "Mean Squared Error: 3.1822\n",
      "Root Mean Squared Error: 1.7839\n"
     ]
    }
   ],
   "source": [
    "test_function(\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_function(\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>FOR PYSPARK MODELS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random forest regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RandomForest_Regressor\").getOrCreate()\n",
    "\n",
    "# Convert pandas DataFrames to Spark DataFrames\n",
    "train_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_train_scaled, columns=X_train.columns), y_train], axis=1))\n",
    "val_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_val_scaled, columns=X_val.columns), y_val], axis=1))\n",
    "test_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_test_scaled, columns=X_test.columns), y_test], axis=1))\n",
    "\n",
    "# Create a list of feature columns\n",
    "feature_columns = train_data.columns\n",
    "feature_columns.remove('overall')\n",
    "\n",
    "# Create a VectorAssembler to combine all feature columns into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Create the Random Forest Regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"overall\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Create a parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 200]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [1, 2, 4]) \\\n",
    "    .build()\n",
    "\n",
    "# Create an evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)  # You can adjust the number of folds\n",
    "\n",
    "# Fit the CrossValidator to the training data\n",
    "print(\"Starting model training and hyperparameter tuning...\")\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# Get the best model\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = bestModel.transform(val_data)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_rmse = evaluator.evaluate(val_predictions)\n",
    "print(f\"Validation Root Mean Squared Error (RMSE) = {val_rmse}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = bestModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "print(f\"Test Root Mean Squared Error (RMSE) = {test_rmse}\")\n",
    "\n",
    "# You can also print other metrics\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(test_predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(test_predictions)\n",
    "print(f\"Test Mean Absolute Error (MAE) = {mae}\")\n",
    "print(f\"Test R2 Score = {r2}\")\n",
    "\n",
    "# Show a few predictions\n",
    "test_predictions.select(\"overall\", \"prediction\").show(5)\n",
    "\n",
    "# Print the best parameters\n",
    "rf_model = bestModel.stages[-1]\n",
    "print(\"Best Parameters:\")\n",
    "print(f\"Number of Trees: {rf_model.getNumTrees}\")\n",
    "print(f\"Max Depth: {rf_model.getMaxDepth}\")\n",
    "print(f\"Min Instances Per Node: {rf_model.getMinInstancesPerNode}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = rf_model.featureImportances\n",
    "for feature, importance in zip(feature_columns, feature_importance):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear Regression Pyspark<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"LinearRegressor\").getOrCreate()\n",
    "\n",
    "# Convert pandas DataFrames to Spark DataFrames\n",
    "train_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_train_scaled, columns=X_train.columns), y_train], axis=1))\n",
    "val_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_val_scaled, columns=X_val.columns), y_val], axis=1))\n",
    "test_data = spark.createDataFrame(pd.concat([pd.DataFrame(X_test_scaled, columns=X_test.columns), y_test], axis=1))\n",
    "\n",
    "# Create a list of feature columns\n",
    "feature_columns = train_data.columns\n",
    "feature_columns.remove('overall')\n",
    "\n",
    "# Create a VectorAssembler to combine all feature columns into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Create the Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"overall\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Create a parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.1, 0.3]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(lr.maxIter, [10, 50, 100]) \\\n",
    "    .build()\n",
    "\n",
    "# Create an evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)  # You can adjust the number of folds\n",
    "\n",
    "# Fit the CrossValidator to the training data\n",
    "print(\"Starting model training and hyperparameter tuning...\")\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# Get the best model\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = bestModel.transform(val_data)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_rmse = evaluator.evaluate(val_predictions)\n",
    "print(f\"Validation Root Mean Squared Error (RMSE) = {val_rmse}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = bestModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "print(f\"Test Root Mean Squared Error (RMSE) = {test_rmse}\")\n",
    "\n",
    "# You can also print other metrics\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(test_predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(test_predictions)\n",
    "print(f\"Test Mean Absolute Error (MAE) = {mae}\")\n",
    "print(f\"Test R2 Score = {r2}\")\n",
    "\n",
    "# Show a few predictions\n",
    "test_predictions.select(\"overall\", \"prediction\").show(5)\n",
    "\n",
    "# Print the best parameters\n",
    "lr_model = bestModel.stages[-1]\n",
    "print(\"Best Parameters:\")\n",
    "print(f\"Regularization Parameter: {lr_model.getRegParam()}\")\n",
    "print(f\"Elastic Net Parameter: {lr_model.getElasticNetParam()}\")\n",
    "print(f\"Max Iterations: {lr_model.getMaxIter()}\")\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(feature_columns, lr_model.coefficients):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "print(f\"Intercept: {lr_model.intercept}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
