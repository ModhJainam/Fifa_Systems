{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Option 1\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/09 14:52:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "appName = \"Big Data Analytics\"\n",
    "master = \"local[*]\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_properties={}\n",
    "db_properties['username']=\"postgres\"\n",
    "db_properties['password']=\"\"\n",
    "db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "db_properties['table']=\"fifa.fifa\"\n",
    "db_properties['driver']=\"org.postgresql.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = spark.read.csv('./Data/players_15.csv', header = True)\n",
    "combined_df = df_male.withColumn(\"year\", lit(2015))\n",
    "combined_df = combined_df.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *combined_df.columns)\n",
    "combined_df = combined_df.withColumn(\"gender\", lit(\"Male\"))\n",
    "folder_path = \"./Data\"\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name == \"players_15.csv\":\n",
    "        continue\n",
    "    year = \"20\" + file_name[-6:-4]\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df_read = spark.read.csv(file_path, header = True)\n",
    "    df_read = df_read.withColumn(\"year\", lit(int(year)))\n",
    "    df_read = df_read.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *df_read.columns)\n",
    "    if \"female\" in file_name:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Female\"))\n",
    "    else:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Male\"))\n",
    "    combined_df = combined_df.union(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to PostgreSQL\n",
    "combined_df.write.format(\"jdbc\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".option(\"url\", db_properties['url'])\\\n",
    ".option(\"dbtable\", db_properties['table'])\\\n",
    ".option(\"user\", db_properties['username'])\\\n",
    ".option(\"password\", db_properties['password'])\\\n",
    ".option(\"Driver\", db_properties['driver'])\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from PostgreSQL to verify\n",
    "df_from_postgres = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", db_properties['url'])\\\n",
    "    .option(\"dbtable\", db_properties['table'])\\\n",
    "    .option(\"user\", db_properties['username'])\\\n",
    "    .option(\"password\", db_properties['password'])\\\n",
    "    .option(\"Driver\", db_properties['driver'])\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id',\n",
       " 'sofifa_id',\n",
       " 'player_url',\n",
       " 'short_name',\n",
       " 'long_name',\n",
       " 'player_positions',\n",
       " 'overall',\n",
       " 'potential',\n",
       " 'value_eur',\n",
       " 'wage_eur',\n",
       " 'age',\n",
       " 'dob',\n",
       " 'height_cm',\n",
       " 'weight_kg',\n",
       " 'club_team_id',\n",
       " 'club_name',\n",
       " 'league_name',\n",
       " 'league_level',\n",
       " 'club_position',\n",
       " 'club_jersey_number',\n",
       " 'club_loaned_from',\n",
       " 'club_joined',\n",
       " 'club_contract_valid_until',\n",
       " 'nationality_id',\n",
       " 'nationality_name',\n",
       " 'nation_team_id',\n",
       " 'nation_position',\n",
       " 'nation_jersey_number',\n",
       " 'preferred_foot',\n",
       " 'weak_foot',\n",
       " 'skill_moves',\n",
       " 'international_reputation',\n",
       " 'work_rate',\n",
       " 'body_type',\n",
       " 'real_face',\n",
       " 'release_clause_eur',\n",
       " 'player_tags',\n",
       " 'player_traits',\n",
       " 'pace',\n",
       " 'shooting',\n",
       " 'passing',\n",
       " 'dribbling',\n",
       " 'defending',\n",
       " 'physic',\n",
       " 'attacking_crossing',\n",
       " 'attacking_finishing',\n",
       " 'attacking_heading_accuracy',\n",
       " 'attacking_short_passing',\n",
       " 'attacking_volleys',\n",
       " 'skill_dribbling',\n",
       " 'skill_curve',\n",
       " 'skill_fk_accuracy',\n",
       " 'skill_long_passing',\n",
       " 'skill_ball_control',\n",
       " 'movement_acceleration',\n",
       " 'movement_sprint_speed',\n",
       " 'movement_agility',\n",
       " 'movement_reactions',\n",
       " 'movement_balance',\n",
       " 'power_shot_power',\n",
       " 'power_jumping',\n",
       " 'power_stamina',\n",
       " 'power_strength',\n",
       " 'power_long_shots',\n",
       " 'mentality_aggression',\n",
       " 'mentality_interceptions',\n",
       " 'mentality_positioning',\n",
       " 'mentality_vision',\n",
       " 'mentality_penalties',\n",
       " 'mentality_composure',\n",
       " 'defending_marking_awareness',\n",
       " 'defending_standing_tackle',\n",
       " 'defending_sliding_tackle',\n",
       " 'goalkeeping_diving',\n",
       " 'goalkeeping_handling',\n",
       " 'goalkeeping_kicking',\n",
       " 'goalkeeping_positioning',\n",
       " 'goalkeeping_reflexes',\n",
       " 'goalkeeping_speed',\n",
       " 'ls',\n",
       " 'st',\n",
       " 'rs',\n",
       " 'lw',\n",
       " 'lf',\n",
       " 'cf',\n",
       " 'rf',\n",
       " 'rw',\n",
       " 'lam',\n",
       " 'cam',\n",
       " 'ram',\n",
       " 'lm',\n",
       " 'lcm',\n",
       " 'cm',\n",
       " 'rcm',\n",
       " 'rm',\n",
       " 'lwb',\n",
       " 'ldm',\n",
       " 'cdm',\n",
       " 'rdm',\n",
       " 'rwb',\n",
       " 'lb',\n",
       " 'lcb',\n",
       " 'cb',\n",
       " 'rcb',\n",
       " 'rb',\n",
       " 'gk',\n",
       " 'player_face_url',\n",
       " 'club_logo_url',\n",
       " 'club_flag_url',\n",
       " 'nation_logo_url',\n",
       " 'nation_flag_url',\n",
       " 'year',\n",
       " 'gender']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144323"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_spark(spark, db_properties):\n",
    "    df_from_postgres = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_properties['url'])\\\n",
    "        .option(\"dbtable\", db_properties['table'])\\\n",
    "        .option(\"user\", db_properties['username'])\\\n",
    "        .option(\"password\", db_properties['password'])\\\n",
    "        .option(\"Driver\", db_properties['driver'])\\\n",
    "        .load()\n",
    "    df = df_from_postgres.filter(df_from_postgres[\"gender\"] == \"Male\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clubs_with_contracts_ending(spark, db_properties, X, Y, Z):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    df_filtered = df.filter(col(\"year\") == X)\n",
    "    df_expiring = df_filtered.filter(col(\"club_contract_valid_until\").cast(\"int\") >= Z)\n",
    "    result = df_expiring.groupBy(\"club_name\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .limit(Y)\n",
    "    return result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clubs_by_average_age(spark, db_properties, X, Y, highest=True):\n",
    "    if X <= 0:\n",
    "        return \"X must be a positive integer\"\n",
    "    if Y < 2015 or Y > 2022:\n",
    "        return \"Y must be a year between 2015 and 2022 inclusively\"\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    \n",
    "    # Filter data for specified year Y\n",
    "    df_filtered = df.filter(col(\"year\") == Y)\n",
    "    avg_age_per_club = df_filtered.groupBy(\"club_name\") \\\n",
    "        .agg(round(avg(\"age\").cast(\"float\"),2).alias(\"average_age\"))\n",
    "    if highest:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(desc(\"average_age\"))\n",
    "    else:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(asc(\"average_age\"))\n",
    "\n",
    "    top_clubs = sorted_clubs.limit(X)\n",
    "    last_club = top_clubs.collect()[-1]\n",
    "    threshold_age = last_club[\"average_age\"]\n",
    "    if highest:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") >= threshold_age).collect()\n",
    "    else:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") <= threshold_age).collect()\n",
    "    return result_clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_popular_nationality(spark, db_properties):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    # df_filtered = df.filter((col(\"year\") >= 2015) & (col(\"year\") <= 2022))\n",
    "    nationality_counts = df.groupBy(\"year\", \"nationality_name\") \\\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "    # Create a window partitioned by year and ordered by count descending\n",
    "    window = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    # Add row number within each year partition\n",
    "    ranked_nationalities = nationality_counts.withColumn(\"rank\", row_number().over(window))\n",
    "    # Filter for the top nationality for each year\n",
    "    most_popular_nationalities = ranked_nationalities.filter(col(\"rank\") == 1) \\\n",
    "        .select(\"year\", \"nationality_name\", \"count\") \\\n",
    "        .orderBy(\"year\")\n",
    "    \n",
    "    return most_popular_nationalities.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clubs = get_top_clubs_with_contracts_ending(spark=spark, db_properties=db_properties, X=2021, Y=10, Z=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='GwangJu FC', count=28),\n",
       " Row(club_name='Zamora Fútbol Club', count=27),\n",
       " Row(club_name='Club Plaza de Deportes Colonia', count=27),\n",
       " Row(club_name='SL Benfica', count=26),\n",
       " Row(club_name='Club Deportivo El Nacional', count=26),\n",
       " Row(club_name='Sociedad Deportiva Aucas', count=26),\n",
       " Row(club_name='Gangwon FC', count=26),\n",
       " Row(club_name='Club Atlético Nacional Potosí', count=26),\n",
       " Row(club_name='Busan IPark', count=26),\n",
       " Row(club_name='Club Sportivo Luqueño', count=25)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs_by_age = find_clubs_by_average_age(spark=spark, db_properties=db_properties, X=10, Y=2017, highest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='Sevilla Atlético', average_age=19.920000076293945),\n",
       " Row(club_name='Swindon Town', average_age=21.3700008392334),\n",
       " Row(club_name='CD Huachipato', average_age=21.40999984741211),\n",
       " Row(club_name='FC Nordsjælland', average_age=21.40999984741211),\n",
       " Row(club_name='FC Twente', average_age=21.59000015258789),\n",
       " Row(club_name='Envigado FC', average_age=21.610000610351562),\n",
       " Row(club_name='KRC Genk', average_age=21.6299991607666),\n",
       " Row(club_name='Crewe Alexandra', average_age=21.81999969482422),\n",
       " Row(club_name='Barnsley', average_age=21.8700008392334),\n",
       " Row(club_name='Ajax', average_age=21.969999313354492)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_by_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_nationalities = get_most_popular_nationality(spark=spark, db_properties=db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2015, nationality_name='England', count=1627),\n",
       " Row(year=2016, nationality_name='England', count=1519),\n",
       " Row(year=2017, nationality_name='England', count=1627),\n",
       " Row(year=2018, nationality_name='England', count=1633),\n",
       " Row(year=2019, nationality_name='England', count=1625),\n",
       " Row(year=2020, nationality_name='England', count=1670),\n",
       " Row(year=2021, nationality_name='England', count=1685),\n",
       " Row(year=2022, nationality_name='England', count=1719)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = read_from_spark(spark, db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF for safe evaluation\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return float(eval(str(x)))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF for trait assignment\n",
    "def assign_traits(player_positions, *traits):\n",
    "    traits = [float(t) if t is not None else None for t in traits]\n",
    "    if player_positions and 'GK' in player_positions:\n",
    "        return traits[6:12]\n",
    "    else:\n",
    "        return traits[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engineering_pipeline(spark_df):\n",
    "    # Drop columns\n",
    "    columns_to_drop = ['record_id', 'sofifa_id', 'player_url', 'short_name', 'long_name',\n",
    "                       'dob', 'club_name', 'league_name', 'club_position', 'club_jersey_number', 'club_loaned_from',\n",
    "                       'club_contract_valid_until', 'nationality_id', 'nationality_name', 'nation_team_id',\n",
    "                       'nation_position', 'nation_jersey_number', 'real_face', 'player_tags', 'player_traits', \n",
    "                       'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url',\n",
    "                       'year', 'gender', 'club_joined']\n",
    "\n",
    "    positions = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw',\n",
    "             'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm',\n",
    "             'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb',\n",
    "             'rcb', 'rb', 'gk']\n",
    "    attacking_positions = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw',\n",
    "                           'lam', 'cam', 'ram']\n",
    "    midfield_positions = ['lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm',\n",
    "                          'ldm', 'cdm', 'rdm']\n",
    "    defensive_positions = ['rwb', 'lb', 'lcb', 'cb', 'lwb', 'rcb', 'rb',\n",
    "                           'ldm', 'cdm', 'rdm']\n",
    "    gk_positions = ['gk']\n",
    "\n",
    "    # Define main traits\n",
    "    main_traits_to_merge = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', \n",
    "                            'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
    "                            'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']\n",
    "\n",
    "    # List of skill columns to average\n",
    "    skill_columns = ['skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control']\n",
    "\n",
    "    #Trait1 = pace/goalkeeping_diving\n",
    "    #Trait2 = shooting/goalkeeping_handling\n",
    "    #Trait3 = passing/goalkeeping_kicking\n",
    "    #Trait4 = dribbling/goalkeeping_positioning\n",
    "    #Trait5 = defending/goalkeeping_reflexes\n",
    "    #Trait6 = physic/goalkeeping_speed\n",
    "    \n",
    "    safe_eval_udf = F.udf(safe_eval, FloatType())\n",
    "    assign_traits_udf = udf(assign_traits, ArrayType(FloatType()))\n",
    "    \n",
    "    #Drop Columns\n",
    "    spark_df = spark_df.drop(*columns_to_drop)\n",
    "    \n",
    "    # Apply safe_eval to position columns\n",
    "    for pos in positions:\n",
    "        spark_df = spark_df.withColumn(pos, safe_eval_udf(pos))\n",
    "\n",
    "    #Add new columns 'average_val_attacking', 'average_val_midfield', 'average_val_defensive', 'average_val_gk'\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_attacking', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in attacking_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in attacking_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_midfield', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in midfield_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in midfield_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_defensive', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in defensive_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in defensive_positions]))\n",
    "        )\n",
    "    )\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'average_val_gk', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in gk_positions]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in gk_positions]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Apply trait assignment\n",
    "    spark_df = spark_df.withColumn('traits', \n",
    "        assign_traits_udf(col('player_positions'), *[col(trait) for trait in main_traits_to_merge])\n",
    "    )\n",
    "    \n",
    "    # Extract individual traits\n",
    "    for i in range(1, 7):\n",
    "        spark_df = spark_df.withColumn(f'trait{i}', col('traits').getItem(i-1))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    spark_df = spark_df.drop(*positions, *main_traits_to_merge, 'player_positions', 'traits')\n",
    "    \n",
    "    # Drop rows with null values in specific columns\n",
    "    spark_df = spark_df.na.drop(subset=['wage_eur', 'value_eur', 'trait6'])\n",
    "    \n",
    "    # Drop additional columns\n",
    "    spark_df = spark_df.drop('release_clause_eur', 'league_level')\n",
    "    \n",
    "    # Fill null values in club_team_id with -1\n",
    "    spark_df = spark_df.fillna({'club_team_id': -1})\n",
    "\n",
    "    #Average out skills as highly correlated\n",
    "    spark_df = spark_df.withColumn(\n",
    "        'corr_av_skills', \n",
    "        F.aggregate(\n",
    "            F.array(*[F.col(pos) for pos in skill_columns]),\n",
    "            F.lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / F.size(F.array(*[F.col(pos) for pos in skill_columns]))\n",
    "        )\n",
    "    )\n",
    "    #Drop the skills as added one new average skill column\n",
    "    spark_df = spark_df.drop('skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control')\n",
    "\n",
    "    #Drop movement_acceleration as highly correlated to movement_speed\n",
    "    spark_df = spark_df.drop('movement_acceleration')\n",
    "\n",
    "    #Drop movement_acceleration as highly correlated to movement_speed\n",
    "    spark_df = spark_df.drop('preferred_foot')\n",
    "\n",
    "    s = spark_df.toPandas()\n",
    "    print(s)\n",
    "    print(f'Shape {s.shape}')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       overall potential    value_eur  wage_eur age height_cm weight_kg  \\\n",
      "0           93        93  103500000.0  560000.0  33       170        72   \n",
      "1           92        92   63000000.0  220000.0  35       187        83   \n",
      "2           91        91  111000000.0  240000.0  31       184        80   \n",
      "3           91        91  132000000.0  270000.0  28       175        68   \n",
      "4           91        91  129000000.0  370000.0  29       181        70   \n",
      "...        ...       ...          ...       ...  ..       ...       ...   \n",
      "140176      59        62     160000.0    3000.0  25       183        76   \n",
      "140177      59        67     230000.0    2000.0  22       177        75   \n",
      "140178      59        73     350000.0    2000.0  20       176        70   \n",
      "140179      59        67     240000.0    3000.0  23       169        57   \n",
      "140180      59        63     160000.0    3000.0  25       176        74   \n",
      "\n",
      "       club_team_id weak_foot skill_moves  ... average_val_midfield  \\\n",
      "0             241.0         4           4  ...            85.363636   \n",
      "1              45.0         4           5  ...            81.727273   \n",
      "2              21.0         4           4  ...            80.545455   \n",
      "3              73.0         5           5  ...            82.545455   \n",
      "4              10.0         5           4  ...            88.818182   \n",
      "...             ...       ...         ...  ...                  ...   \n",
      "140176     112510.0         3           1  ...            23.727273   \n",
      "140177       1443.0         3           2  ...            53.000000   \n",
      "140178         17.0         3           2  ...            52.454545   \n",
      "140179     112395.0         4           3  ...            50.909091   \n",
      "140180     112172.0         3           2  ...            52.636364   \n",
      "\n",
      "       average_val_defensive average_val_gk trait1 trait2 trait3 trait4  \\\n",
      "0                       63.7           22.0   85.0   92.0   91.0   95.0   \n",
      "1                       62.7           23.0   89.0   93.0   81.0   89.0   \n",
      "2                       65.5           22.0   78.0   91.0   78.0   85.0   \n",
      "3                       62.1           23.0   91.0   85.0   86.0   94.0   \n",
      "4                       78.5           24.0   76.0   86.0   93.0   88.0   \n",
      "...                      ...            ...    ...    ...    ...    ...   \n",
      "140176                  22.6           59.0   61.0   60.0   54.0   59.0   \n",
      "140177                  44.2           16.0   77.0   51.0   54.0   58.0   \n",
      "140178                  39.4           14.0   61.0   57.0   58.0   65.0   \n",
      "140179                  38.5           16.0   91.0   55.0   45.0   66.0   \n",
      "140180                  57.5           16.0   70.0   40.0   51.0   58.0   \n",
      "\n",
      "       trait5 trait6 corr_av_skills  \n",
      "0        38.0   65.0           94.0  \n",
      "1        35.0   77.0           82.8  \n",
      "2        43.0   82.0           81.4  \n",
      "3        36.0   59.0           89.6  \n",
      "4        64.0   78.0           88.2  \n",
      "...       ...    ...            ...  \n",
      "140176   59.0   31.0           16.4  \n",
      "140177   27.0   61.0           51.4  \n",
      "140178   24.0   50.0           59.4  \n",
      "140179   19.0   48.0           43.6  \n",
      "140180   58.0   59.0           49.8  \n",
      "\n",
      "[140181 rows x 47 columns]\n",
      "Shape (140181, 47)\n"
     ]
    }
   ],
   "source": [
    "s = data_engineering_pipeline(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From correlation analysis\n",
    "average - skill columns\n",
    "remove - movement_acceleration\n",
    "Preffered foot is not correlated to overall. so drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
