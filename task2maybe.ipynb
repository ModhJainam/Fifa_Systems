{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd2c31f-ca0a-4024-a151-a4f744698168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def get_top_clubs_with_contracts_ending(spark, X, Y, Z):\n",
    "    connection_properties = {\n",
    "        'user': 'your_username',\n",
    "        'password': 'your_password',\n",
    "        'driver': 'org.postgresql.Driver'\n",
    "    }\n",
    "    \n",
    "    df = spark.read.jdbc(\n",
    "        url='jdbc:postgresql://localhost:5432/your_database',\n",
    "        table='players',\n",
    "        properties=connection_properties\n",
    "    )\n",
    "\n",
    "    filtered_df = df.filter(\n",
    "        (F.col('club_contract_valid_until') >= Z) & \n",
    "        (F.year(F.col('club_joined')) == X)\n",
    "    )\n",
    "\n",
    "    clubs_count = filtered_df.groupBy('club_name').count()\n",
    "    top_clubs = clubs_count.orderBy('count', ascending=False).limit(Y)\n",
    "    \n",
    "    return top_clubs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a60c0b1-b503-46e9-ab35-432e542a43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clubs_with_average_age(spark, X, Y, is_highest=True):\n",
    "    connection_properties = {\n",
    "        'user': 'your_username',\n",
    "        'password': 'your_password',\n",
    "        'driver': 'org.postgresql.Driver'\n",
    "    }\n",
    "    \n",
    "    df = spark.read.jdbc(\n",
    "        url='jdbc:postgresql://localhost:5432/your_database',\n",
    "        table='players',\n",
    "        properties=connection_properties\n",
    "    )\n",
    "\n",
    "    filtered_df = df.filter(F.year(F.col('dob')) == Y)\n",
    "    \n",
    "    now = F.current_date()\n",
    "    aged_df = filtered_df.withColumn('age', F.year(now) - F.year(F.col('dob')))\n",
    "\n",
    "    clubs_avg_age = aged_df.groupBy('club_name').agg(F.avg('age').alias('avg_age'))\n",
    "\n",
    "    if X <= 0:\n",
    "        return []\n",
    "    \n",
    "    ordered_clubs = clubs_avg_age.orderBy('avg_age', ascending=not is_highest)\n",
    "    top_X = ordered_clubs.limit(X).collect()\n",
    "    \n",
    "    if len(top_X) == X:\n",
    "        last_avg_age = top_X[-1]['avg_age']\n",
    "        additional = ordered_clubs.filter(F.col('avg_age') == last_avg_age).collect()\n",
    "        top_X.extend([club for club in additional if club not in top_X])\n",
    "\n",
    "    return top_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1265230c-2c1e-4a86-a505-02be7f6cef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_popular_nationality(spark):\n",
    "    connection_properties = {\n",
    "        'user': 'your_username',\n",
    "        'password': 'your_password',\n",
    "        'driver': 'org.postgresql.Driver'\n",
    "    }\n",
    "    \n",
    "    df = spark.read.jdbc(\n",
    "        url='jdbc:postgresql://localhost:5432/your_database',\n",
    "        table='players',\n",
    "        properties=connection_properties\n",
    "    )\n",
    "\n",
    "    most_popular_nationalities = {}\n",
    "    \n",
    "    for year in range(2015, 2023):\n",
    "        year_df = df.filter(F.year(F.col('dob')) == year)\n",
    "        nationality_counts = year_df.groupBy('nationality_name').count()\n",
    "        most_popular = nationality_counts.orderBy('count', ascending=False).first()\n",
    "        most_popular_nationalities[year] = most_popular['nationality_name'] if most_popular else None\n",
    "    \n",
    "    return most_popular_nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9a087e-de02-4a7c-b5c9-bca44ccf634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/06 19:16:51 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "appName = \"Big Data Analytics\"\n",
    "master = \"local[*]\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .set(\"spark.drive.memory\", \"10g\")\\\n",
    "    .set(\"spark.executor.memory\", \"10g\")\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a03d5-58ca-4546-a652-f3cf2920e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clubs = get_top_clubs_with_contracts_ending(spark, 2020, 5, 2023)\n",
    "clubs_by_age = get_clubs_with_average_age(spark, 10, 2022, is_highest=True)\n",
    "popular_nationalities = get_most_popular_nationality(spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
