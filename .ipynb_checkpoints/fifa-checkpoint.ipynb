{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Option 1\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 17:37:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "appName = \"Big Data Analytics\"\n",
    "master = \"local[*]\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_properties={}\n",
    "db_properties['username']=\"postgres\"\n",
    "db_properties['password']=\"\"\n",
    "db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "db_properties['table']=\"fifa.fifa\"\n",
    "db_properties['driver']=\"org.postgresql.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = spark.read.csv('./Data/players_15.csv', header = True)\n",
    "combined_df = df_male.withColumn(\"year\", lit(2015))\n",
    "combined_df = combined_df.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *combined_df.columns)\n",
    "combined_df = combined_df.withColumn(\"gender\", lit(\"Male\"))\n",
    "folder_path = \"./Data\"\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name == \"players_15.csv\":\n",
    "        continue\n",
    "    year = \"20\" + file_name[-6:-4]\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df_read = spark.read.csv(file_path, header = True)\n",
    "    df_read = df_read.withColumn(\"year\", lit(int(year)))\n",
    "    df_read = df_read.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *df_read.columns)\n",
    "    if \"female\" in file_name:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Female\"))\n",
    "    else:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Male\"))\n",
    "    combined_df = combined_df.union(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 17:38:08 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to PostgreSQL\n",
    "combined_df.write.format(\"jdbc\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".option(\"url\", db_properties['url'])\\\n",
    ".option(\"dbtable\", db_properties['table'])\\\n",
    ".option(\"user\", db_properties['username'])\\\n",
    ".option(\"password\", db_properties['password'])\\\n",
    ".option(\"Driver\", db_properties['driver'])\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from PostgreSQL to verify\n",
    "df_from_postgres = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", db_properties['url'])\\\n",
    "    .option(\"dbtable\", db_properties['table'])\\\n",
    "    .option(\"user\", db_properties['username'])\\\n",
    "    .option(\"password\", db_properties['password'])\\\n",
    "    .option(\"Driver\", db_properties['driver'])\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id',\n",
       " 'sofifa_id',\n",
       " 'player_url',\n",
       " 'short_name',\n",
       " 'long_name',\n",
       " 'player_positions',\n",
       " 'overall',\n",
       " 'potential',\n",
       " 'value_eur',\n",
       " 'wage_eur',\n",
       " 'age',\n",
       " 'dob',\n",
       " 'height_cm',\n",
       " 'weight_kg',\n",
       " 'club_team_id',\n",
       " 'club_name',\n",
       " 'league_name',\n",
       " 'league_level',\n",
       " 'club_position',\n",
       " 'club_jersey_number',\n",
       " 'club_loaned_from',\n",
       " 'club_joined',\n",
       " 'club_contract_valid_until',\n",
       " 'nationality_id',\n",
       " 'nationality_name',\n",
       " 'nation_team_id',\n",
       " 'nation_position',\n",
       " 'nation_jersey_number',\n",
       " 'preferred_foot',\n",
       " 'weak_foot',\n",
       " 'skill_moves',\n",
       " 'international_reputation',\n",
       " 'work_rate',\n",
       " 'body_type',\n",
       " 'real_face',\n",
       " 'release_clause_eur',\n",
       " 'player_tags',\n",
       " 'player_traits',\n",
       " 'pace',\n",
       " 'shooting',\n",
       " 'passing',\n",
       " 'dribbling',\n",
       " 'defending',\n",
       " 'physic',\n",
       " 'attacking_crossing',\n",
       " 'attacking_finishing',\n",
       " 'attacking_heading_accuracy',\n",
       " 'attacking_short_passing',\n",
       " 'attacking_volleys',\n",
       " 'skill_dribbling',\n",
       " 'skill_curve',\n",
       " 'skill_fk_accuracy',\n",
       " 'skill_long_passing',\n",
       " 'skill_ball_control',\n",
       " 'movement_acceleration',\n",
       " 'movement_sprint_speed',\n",
       " 'movement_agility',\n",
       " 'movement_reactions',\n",
       " 'movement_balance',\n",
       " 'power_shot_power',\n",
       " 'power_jumping',\n",
       " 'power_stamina',\n",
       " 'power_strength',\n",
       " 'power_long_shots',\n",
       " 'mentality_aggression',\n",
       " 'mentality_interceptions',\n",
       " 'mentality_positioning',\n",
       " 'mentality_vision',\n",
       " 'mentality_penalties',\n",
       " 'mentality_composure',\n",
       " 'defending_marking_awareness',\n",
       " 'defending_standing_tackle',\n",
       " 'defending_sliding_tackle',\n",
       " 'goalkeeping_diving',\n",
       " 'goalkeeping_handling',\n",
       " 'goalkeeping_kicking',\n",
       " 'goalkeeping_positioning',\n",
       " 'goalkeeping_reflexes',\n",
       " 'goalkeeping_speed',\n",
       " 'ls',\n",
       " 'st',\n",
       " 'rs',\n",
       " 'lw',\n",
       " 'lf',\n",
       " 'cf',\n",
       " 'rf',\n",
       " 'rw',\n",
       " 'lam',\n",
       " 'cam',\n",
       " 'ram',\n",
       " 'lm',\n",
       " 'lcm',\n",
       " 'cm',\n",
       " 'rcm',\n",
       " 'rm',\n",
       " 'lwb',\n",
       " 'ldm',\n",
       " 'cdm',\n",
       " 'rdm',\n",
       " 'rwb',\n",
       " 'lb',\n",
       " 'lcb',\n",
       " 'cb',\n",
       " 'rcb',\n",
       " 'rb',\n",
       " 'gk',\n",
       " 'player_face_url',\n",
       " 'club_logo_url',\n",
       " 'club_flag_url',\n",
       " 'nation_logo_url',\n",
       " 'nation_flag_url',\n",
       " 'year',\n",
       " 'gender']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144323"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_postgres.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_spark(spark, db_properties):\n",
    "    df_from_postgres = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_properties['url'])\\\n",
    "        .option(\"dbtable\", db_properties['table'])\\\n",
    "        .option(\"user\", db_properties['username'])\\\n",
    "        .option(\"password\", db_properties['password'])\\\n",
    "        .option(\"Driver\", db_properties['driver'])\\\n",
    "        .load()\n",
    "    df = df_from_postgres.filter(df_from_postgres[\"gender\"] == \"Male\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clubs_with_contracts_ending(spark, db_properties, X, Y, Z):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    df_filtered = df.filter(col(\"year\") == X)\n",
    "    df_expiring = df_filtered.filter(col(\"club_contract_valid_until\").cast(\"int\") >= Z)\n",
    "    result = df_expiring.groupBy(\"club_name\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .limit(Y)\n",
    "    return result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clubs_by_average_age(spark, db_properties, X, Y, highest=True):\n",
    "    if X <= 0:\n",
    "        return \"X must be a positive integer\"\n",
    "    if Y < 2015 or Y > 2022:\n",
    "        return \"Y must be a year between 2015 and 2022 inclusively\"\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    \n",
    "    # Filter data for specified year Y\n",
    "    df_filtered = df.filter(col(\"year\") == Y)\n",
    "    avg_age_per_club = df_filtered.groupBy(\"club_name\") \\\n",
    "        .agg(round(avg(\"age\").cast(\"float\"),2).alias(\"average_age\"))\n",
    "    if highest:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(desc(\"average_age\"))\n",
    "    else:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(asc(\"average_age\"))\n",
    "\n",
    "    top_clubs = sorted_clubs.limit(X)\n",
    "    last_club = top_clubs.collect()[-1]\n",
    "    threshold_age = last_club[\"average_age\"]\n",
    "    if highest:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") >= threshold_age).collect()\n",
    "    else:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") <= threshold_age).collect()\n",
    "    return result_clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_popular_nationality(spark, db_properties):\n",
    "    df = read_from_spark(spark, db_properties)\n",
    "    # df_filtered = df.filter((col(\"year\") >= 2015) & (col(\"year\") <= 2022))\n",
    "    nationality_counts = df.groupBy(\"year\", \"nationality_name\") \\\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "    # Create a window partitioned by year and ordered by count descending\n",
    "    window = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    # Add row number within each year partition\n",
    "    ranked_nationalities = nationality_counts.withColumn(\"rank\", row_number().over(window))\n",
    "    # Filter for the top nationality for each year\n",
    "    most_popular_nationalities = ranked_nationalities.filter(col(\"rank\") == 1) \\\n",
    "        .select(\"year\", \"nationality_name\", \"count\") \\\n",
    "        .orderBy(\"year\")\n",
    "    \n",
    "    return most_popular_nationalities.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clubs = get_top_clubs_with_contracts_ending(spark, db_properties, 2021, 10, 2023)\n",
    "clubs_by_age = find_clubs_by_average_age(spark, db_properties, 10, 2017, highest=False)\n",
    "popular_nationalities = get_most_popular_nationality(spark, db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='GwangJu FC', count=28),\n",
       " Row(club_name='Zamora Fútbol Club', count=27),\n",
       " Row(club_name='Club Plaza de Deportes Colonia', count=27),\n",
       " Row(club_name='SL Benfica', count=26),\n",
       " Row(club_name='Club Deportivo El Nacional', count=26),\n",
       " Row(club_name='Sociedad Deportiva Aucas', count=26),\n",
       " Row(club_name='Gangwon FC', count=26),\n",
       " Row(club_name='Club Atlético Nacional Potosí', count=26),\n",
       " Row(club_name='Busan IPark', count=26),\n",
       " Row(club_name='Club Sportivo Luqueño', count=25)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='Sevilla Atlético', average_age=19.920000076293945),\n",
       " Row(club_name='Swindon Town', average_age=21.3700008392334),\n",
       " Row(club_name='CD Huachipato', average_age=21.40999984741211),\n",
       " Row(club_name='FC Nordsjælland', average_age=21.40999984741211),\n",
       " Row(club_name='FC Twente', average_age=21.59000015258789),\n",
       " Row(club_name='Envigado FC', average_age=21.610000610351562),\n",
       " Row(club_name='KRC Genk', average_age=21.6299991607666),\n",
       " Row(club_name='Crewe Alexandra', average_age=21.81999969482422),\n",
       " Row(club_name='Barnsley', average_age=21.8700008392334),\n",
       " Row(club_name='Ajax', average_age=21.969999313354492)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_by_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2015, nationality_name='England', count=1627),\n",
       " Row(year=2016, nationality_name='England', count=1519),\n",
       " Row(year=2017, nationality_name='England', count=1627),\n",
       " Row(year=2018, nationality_name='England', count=1633),\n",
       " Row(year=2019, nationality_name='England', count=1625),\n",
       " Row(year=2020, nationality_name='England', count=1670),\n",
       " Row(year=2021, nationality_name='England', count=1685),\n",
       " Row(year=2022, nationality_name='England', count=1719)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_nationalities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
